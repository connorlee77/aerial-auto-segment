{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T00:49:44.693489423Z",
     "start_time": "2023-06-22T00:49:44.679683459Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "0.284083 seconds to read csvs\n",
      "Creating new camera matrix...\n",
      "(1, 23361, 24769)\n",
      "(1, 23361, 24769)\n",
      "423.878205 seconds to read rasters\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from horizon.flir_boson_settings import I, D, P\n",
    "\n",
    "import pickle\n",
    "import tqdm\n",
    "from scipy.spatial.transform import Rotation\n",
    "from scipy.interpolate import RegularGridInterpolator, NearestNDInterpolator\n",
    "\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "import rasterio.merge\n",
    "import rasterio.mask\n",
    "import pyproj\n",
    "from PIL import ImageColor\n",
    "import shapely\n",
    "from shapely import Polygon\n",
    "import skimage \n",
    "\n",
    "from utils.utils import thermal2rgb\n",
    "from utils.projections import (\n",
    "    project_points, \n",
    "    power_spacing, \n",
    "    world2cam, \n",
    "    create_world_grid,\n",
    "    world_to_camera_coords,\n",
    ")\n",
    "\n",
    "from utils.draw import (\n",
    "    draw_overlay_and_labels, \n",
    "    points_to_segmentation, \n",
    "    generate_binary_mask,\n",
    "    colorize_dynamic_world_label,\n",
    "    dynamic_world_color_map,\n",
    "    chesapeake_cvpr_landcover_color_map,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "### Set path to flight sequence folder containing images and csv files.\n",
    "##########################################################################\n",
    "# DATA_PATH = '/data/onr-thermal/2022-12-20_Castaic_Lake/flight4'\n",
    "# DATA_PATH = '/data/onr-thermal/2022-05-15_ColoradoRiver/flight3'\n",
    "DATA_PATH = '/data/onr-thermal/caltech_duck/ONR_2023-03-22-14-41-46'\n",
    "# DATA_PATH = '/data/onr-thermal/big_bear/ONR_2022-05-08-11-23-59'\n",
    "# DATA_PATH = '/data/onr-thermal/kentucky_river/flight3-1'\n",
    "\n",
    "BASE_PATH = '/data/microsoft_planetary_computer/outputs/preprocessed/'\n",
    "EPSG = 'epsg-32618'\n",
    "PLACE = 'duck'\n",
    "LULC_TYPE = 'dynamicworld'\n",
    "D3_TYPE = 'dsm'\n",
    "RESOLUTION = '0.6'\n",
    "\n",
    "# BASELINE_ELEVATION = 428.54 # Water elevation of Castaic Lake, Dec. 22, 2022\n",
    "# BASELINE_ELEVATION = 0 # Water elevation of Colorado River, Parker Dam\n",
    "# BASELINE_ELEVATION = 114 # Water elevation of Colorado River, Parker Dam\n",
    "# BASELINE_ELEVATION = 2058 # Water elevation of big bear lake\n",
    "# BASELINE_ELEVATION = 177 # kentucky river\n",
    "BASELINE_ELEVATION = 0 # duck\n",
    "\n",
    "LABEL_RASTER_PATH = os.path.join(BASE_PATH, EPSG, PLACE, LULC_TYPE, RESOLUTION, 'crf_naip_naip-nir', 'mosaic.tiff')\n",
    "DSM_PATH = os.path.join(BASE_PATH, EPSG, PLACE, D3_TYPE, RESOLUTION, 'mosaic.tiff')\n",
    "\n",
    "##########################################################################\n",
    "### Create output folders\n",
    "##########################################################################\n",
    "if os.path.exists('outputs') and os.path.isdir('outputs'):\n",
    "    shutil.rmtree('outputs')\n",
    "os.makedirs('outputs')\n",
    "\n",
    "color_map = dynamic_world_color_map()\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "### Read csv of uav global/local pose\n",
    "##########################################################################\n",
    "print('Reading data...')\n",
    "t0 = time.time()\n",
    "alignment_data = pd.read_csv(os.path.join(DATA_PATH, \"aligned.csv\"), header=13)\n",
    "# alignment_data = pd.read_csv(os.path.join(DATA_PATH, \"aligned.csv\"), header=14)\n",
    "# alignment_data = pd.read_csv(os.path.join(DATA_PATH, \"aligned.csv\"), header=0)\n",
    "\n",
    "alignment_data = alignment_data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "alignment_data.columns = alignment_data.columns.str.replace(' ', '')\n",
    "t1 = time.time()\n",
    "print('{:3f} seconds to read csvs'.format(t1 - t0))\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "### Get rectified camera matrix\n",
    "##########################################################################\n",
    "print('Creating new camera matrix...')\n",
    "H, W = (512, 640)\n",
    "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(I, D, (W, H), 0, (W, H))\n",
    "new_P = np.hstack([newcameramtx, np.zeros((3,1))])\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "### Read raster data (dynamic world labels + dsm)\n",
    "##########################################################################\n",
    "t0 = time.time()\n",
    "label_tiff_data = rasterio.open(LABEL_RASTER_PATH)\n",
    "dsm = rasterio.open(DSM_PATH)\n",
    "\n",
    "if os.path.exists('dw_interp.pkl') and os.path.exists('dsm_interp.pkl'):\n",
    "    with open('dw_interp.pkl', 'rb') as f:\n",
    "        label_interp = pickle.load(f)\n",
    "    \n",
    "    with open('dsm_interp.pkl', 'rb') as f:\n",
    "        dsm_interp = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    label_array = label_tiff_data.read()\n",
    "    dsm_array = dsm.read()\n",
    "\n",
    "    print(label_array.shape)\n",
    "    n_bands, height, width = label_array.shape\n",
    "    cols, rows = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    xs, ys = rasterio.transform.xy(label_tiff_data.transform, rows, cols)\n",
    "    label_utm_grid = np.stack([xs, ys], axis=2).reshape(-1, 2)\n",
    "    label_interp = NearestNDInterpolator(label_utm_grid, label_array.transpose(1, 2, 0).reshape(height*width, n_bands))\n",
    "\n",
    "    with open('dw_interp.pkl', 'wb') as f:\n",
    "        pickle.dump(label_interp, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(dsm_array.shape)\n",
    "    n_bands, height, width = dsm_array.shape\n",
    "    cols, rows = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    xs, ys = rasterio.transform.xy(dsm.transform, rows, cols)\n",
    "    dsm_utm_grid = np.stack([xs, ys], axis=2).reshape(-1, 2)\n",
    "    dsm_interp = NearestNDInterpolator(dsm_utm_grid, dsm_array.transpose(1, 2, 0).reshape(height*width, 1))\n",
    "    with open('dsm_interp.pkl', 'wb') as f:\n",
    "        pickle.dump(dsm_interp, f, pickle.HIGHEST_PROTOCOL)\n",
    "t1 = time.time()\n",
    "print('{:3f} seconds to read rasters'.format(t1 - t0))\n",
    "\n",
    "crs = label_tiff_data.crs\n",
    "tform = pyproj.Transformer.from_crs(\"epsg:4326\", \"epsg:{}\".format(crs.to_epsg()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moderngl\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "from PIL import ImageColor\n",
    "import pyvista as pv\n",
    "\n",
    "def glOrtho(left, right, bottom, top, near, far):\n",
    "    tx = -(right + left) / (right - left)\n",
    "    ty = -(top + bottom) / (top - bottom)\n",
    "    tz = -(far + near) / (far - near)\n",
    "    x = np.array([\n",
    "        [2 / (right - left), 0, 0, tx],\n",
    "        [0, 2 / (top - bottom), 0, ty],\n",
    "        [0, 0, -2 / (far - near), tz],\n",
    "        [0, 0, 0, 1],\n",
    "    ], dtype='f4')\n",
    "    return x\n",
    "\n",
    "HEX_COLORS = [\n",
    "    '#419BDF', '#397D49', '#88B053', '#7A87C6', '#E49635', '#DFC35A',\n",
    "    '#C4281B', '#ffffff', '#B39FE1', '#A8DEFF'\n",
    "]\n",
    "    \n",
    "# K_gl = np.zeros((4,4), dtype='f4')\n",
    "# K_gl[0,0] = -I[0,0]\n",
    "# K_gl[1,1] = -I[1,1]\n",
    "# K_gl[0,2] = (cols - I[0,2])\n",
    "# K_gl[1,2] = (rows - I[1,2])\n",
    "# K_gl[2,2] = A\n",
    "# K_gl[2,3] = B\n",
    "# K_gl[3,2] = 1\n",
    "\n",
    "# NDC = np.zeros((4,4), dtype='f4')\n",
    "# NDC[0,0] = -2 / cols\n",
    "# NDC[1,1] = 2 / rows\n",
    "# NDC[2,2] = -2 / (far - near)\n",
    "\n",
    "# NDC[0,3] = 1\n",
    "# NDC[1,3] = -1\n",
    "# NDC[2,3] = -(far + near) / (far - near)\n",
    "# NDC[3,3] = 1\n",
    "\n",
    "\n",
    "\n",
    "def dynamic_world_color_map():\n",
    "    rgb_colors = [ImageColor.getcolor(c, \"RGB\") for c in HEX_COLORS]\n",
    "    color_map = dict(zip(list(range(0, 10)), rgb_colors))\n",
    "    return color_map\n",
    "\n",
    "def colorize_dynamic_world_label(label):\n",
    "    mapping = dynamic_world_color_map()\n",
    "\n",
    "    h = len(label)\n",
    "    color_label = np.zeros((h, 3), dtype=np.uint8)\n",
    "    for i in range(0, 10):\n",
    "        color_label[label == i, :] = mapping[i] \n",
    "    return color_label / 255\n",
    "\n",
    "def get_mask_mgl(pts, label):\n",
    "\n",
    "    # Intrinsics matrix\n",
    "    I_old = np.array([\n",
    "        [511.03573247, 0.000000, 311.80346835], \n",
    "        [0.000000, 508.22913692, 261.56701122], \n",
    "        [0.000000, 0.000000, 1.000000]\n",
    "    ])\n",
    "    D = np.array([-0.43339599, 0.18974767, -0.00146426, 0.00118333, 0.000000])\n",
    "\n",
    "    H, W = (512, 640)\n",
    "    I, roi = cv2.getOptimalNewCameraMatrix(I_old, D, (W, H), 0, (W, H))\n",
    "    # print(I)\n",
    "    near = 0.1\n",
    "    far = 10000\n",
    "    rows = 512\n",
    "    cols = 640\n",
    "    A = -(near + far)\n",
    "    B  = near * far\n",
    "    \n",
    "    K_gl = np.array([\n",
    "        [I[0,0], 0, -I[0,2], 0],\n",
    "        [0, I[1,1], -I[1,2], 0],\n",
    "        [0, 0, near+far, near*far],\n",
    "        [0, 0, -1, 0],\n",
    "    ], dtype='f4')\n",
    "    NDC = glOrtho(0, cols, rows, 0, near, far)\n",
    "\n",
    "    P_gl = NDC @ K_gl\n",
    "    # pts = np.load('outputs/thermal-10000.npy').T\n",
    "\n",
    "    xyz = pts[[1, 2, 0], :].T\n",
    "    xyz[:,2] *= -1\n",
    "    xyz[:,0] *= -1\n",
    "\n",
    "    # print(\"Input Label: \", label.shape)\n",
    "    label = pts[3,:].T\n",
    "    # print(\"After: \", label.shape)\n",
    "\n",
    "    # num_vertices = xyz.shape[0]\n",
    "    color = colorize_dynamic_world_label(label)\n",
    "    # colors = np.hstack([color, np.ones(num_vertices).reshape(-1,1)])\n",
    "\n",
    "    cloud = pv.PolyData(xyz)\n",
    "    surf = cloud.delaunay_2d()\n",
    "    print(surf.point_normals)\n",
    "    vertex_normals = surf.point_normals\n",
    "    vertices = surf.points\n",
    "    vertex_colors = color\n",
    "\n",
    "    faces = surf.faces.reshape(-1, 4)\n",
    "    triangles = faces[:,1:]\n",
    "\n",
    "    # -------------------\n",
    "    # CREATE CONTEXT HERE\n",
    "    # -------------------\n",
    "\n",
    "    with moderngl.create_context(standalone=True, backend='egl') as ctx:\n",
    "\n",
    "        prog = ctx.program(\n",
    "            vertex_shader='''\n",
    "                #version 330\n",
    "                uniform mat4 proj;\n",
    "\n",
    "                in vec3 in_vert;\n",
    "                in vec3 in_color;\n",
    "\n",
    "                out vec3 v_color;\n",
    "                out vec4 pose;\n",
    "\n",
    "                void main() {\n",
    "                    v_color = in_color;\n",
    "                    pose = proj*vec4(in_vert, 1.0);\n",
    "                    gl_Position = proj*vec4(in_vert, 1.0);\n",
    "                }\n",
    "            ''',\n",
    "            fragment_shader='''\n",
    "                #version 330\n",
    "\n",
    "                in vec3 v_color;\n",
    "                out vec3 f_color;\n",
    "\n",
    "                void main() {\n",
    "                    f_color = v_color;\n",
    "                }\n",
    "            ''',\n",
    "            varyings=['pose']\n",
    "        )\n",
    "\n",
    "        P_gl = np.ascontiguousarray(P_gl.T)\n",
    "        prog['proj'].write(P_gl)\n",
    "        \n",
    "        vertices_info = np.hstack([vertices, vertex_colors]).astype('f4')\n",
    "\n",
    "        fbo = ctx.simple_framebuffer((640, 512))\n",
    "        fbo.use()\n",
    "        \n",
    "        ctx.enable(moderngl.DEPTH_TEST)\n",
    "        ibo = ctx.buffer(triangles.astype('i4'))\n",
    "        vbo = ctx.buffer(vertices_info.astype('f4'))\n",
    "        vao = ctx.vertex_array(\n",
    "            prog, \n",
    "            [(vbo, '3f 3f', 'in_vert', 'in_color')],\n",
    "            ibo,\n",
    "        )\n",
    "\n",
    "        vao.render(moderngl.TRIANGLES)\n",
    "        image = Image.frombytes('RGB', fbo.size, fbo.read(), 'raw', 'RGB', 0, 1)\n",
    "        image.save('output.png')\n",
    "        print(ctx.error)\n",
    "        # Return as np array for plotting over original image\n",
    "    return np.asarray(image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting segmentation estimation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/35 [00:07<04:18,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00118662  0.9999833   0.00564619]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " ...\n",
      " [ 0.00474865  0.9158474   0.40149838]\n",
      " [ 0.00474865  0.9158474   0.40149838]\n",
      " [ 0.00474865  0.91584754  0.40149844]]\n",
      "GL_NO_ERROR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2/35 [00:14<03:50,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14377324 0.79661256 0.5871436 ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " ...\n",
      " [0.14377326 0.7966127  0.58714366]\n",
      " [0.14377326 0.7966127  0.58714366]\n",
      " [0.14377324 0.79661256 0.5871436 ]]\n",
      "GL_NO_ERROR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 3/35 [00:21<03:48,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0794169  0.75219125 0.6541418 ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " ...\n",
      " [0.07981312 0.86507887 0.49524596]\n",
      " [0.07981312 0.86507887 0.49524596]\n",
      " [0.07981311 0.8650788  0.4952459 ]]\n",
      "GL_NO_ERROR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 4/35 [00:29<03:46,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.39824978  0.77249986 -0.49461192]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " ...\n",
      " [ 0.10911317  0.8889362   0.4448447 ]\n",
      " [ 0.10911317  0.8889362   0.4448447 ]\n",
      " [ 0.10911316  0.88893616  0.4448447 ]]\n",
      "GL_NO_ERROR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 5/35 [00:36<03:41,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10301533 0.9115288  0.3981244 ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " ...\n",
      " [0.1027948  0.91154945 0.39813444]\n",
      " [0.1027948  0.91154945 0.39813444]\n",
      " [0.10279478 0.9115493  0.3981344 ]]\n",
      "GL_NO_ERROR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 6/35 [00:44<03:39,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08475045 0.8732952  0.47976342]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " ...\n",
      " [0.08501433 0.9080696  0.41010016]\n",
      " [0.08501433 0.9080696  0.41010016]\n",
      " [0.08501433 0.9080696  0.41010013]]\n",
      "GL_NO_ERROR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 7/35 [00:51<03:28,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14166117 0.76199645 0.6318968 ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " ...\n",
      " [0.14307539 0.84429336 0.51642835]\n",
      " [0.14307539 0.84429336 0.51642835]\n",
      " [0.14307539 0.84429336 0.5164283 ]]\n",
      "GL_NO_ERROR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 8/35 [01:01<03:39,  8.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04599185 -0.8653282  -0.49909106]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " ...\n",
      " [ 0.04599185 -0.8653282  -0.4990911 ]\n",
      " [ 0.04599185 -0.8653282  -0.4990911 ]\n",
      " [ 0.04599185 -0.8653282  -0.4990911 ]]\n",
      "GL_NO_ERROR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 9/35 [01:11<03:52,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11707334 -0.79319274 -0.5976111 ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " ...\n",
      " [ 0.13177991 -0.8857805  -0.44500214]\n",
      " [ 0.20735303 -0.9294345  -0.3052151 ]\n",
      " [ 0.1176472  -0.9670821  -0.22563596]]\n",
      "GL_NO_ERROR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 9/35 [01:13<03:31,  8.12s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 146\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m### SARASWATI: dig into world2cam to find where the word_coord_pts get transformed into the \u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m### camera coordinate frame (3D), and subsequently, projected into the 2D image frame. \u001b[39;00m\n\u001b[1;32m    144\u001b[0m Xn \u001b[38;5;241m=\u001b[39m world2cam(cam_xyzw, new_P, word_coord_pts)\n\u001b[0;32m--> 146\u001b[0m original_img, masked_img, pts_img \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_overlay_and_labels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mundistorted_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mXn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworld_coord_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_map\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(img_path)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    154\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name), original_img)\n",
      "File \u001b[0;32m~/repos/aerial-auto-segment/utils/draw.py:279\u001b[0m, in \u001b[0;36mdraw_overlay_and_labels\u001b[0;34m(img, points, labels, color_map, alpha)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# Generate a binary mask from the original points\u001b[39;00m\n\u001b[1;32m    278\u001b[0m binary_mask \u001b[38;5;241m=\u001b[39m generate_binary_mask(img_shape, points)\n\u001b[0;32m--> 279\u001b[0m colorized_mask \u001b[38;5;241m=\u001b[39m \u001b[43mpoints_to_segmentation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;66;03m# Overlay the colorized segmentation mask on the image\u001b[39;00m\n\u001b[1;32m    283\u001b[0m overlay \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39maddWeighted(orig_img, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alpha, colorized_mask, alpha, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/repos/aerial-auto-segment/utils/draw.py:172\u001b[0m, in \u001b[0;36mpoints_to_segmentation\u001b[0;34m(img_shape, points, labels, color_map, mask)\u001b[0m\n\u001b[1;32m    169\u001b[0m tree \u001b[38;5;241m=\u001b[39m KDTree(points)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Find nearest neighbors for each pixel in the image\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m _, nearest_neighbors \u001b[38;5;241m=\u001b[39m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Create segmentation mask using the labels of the nearest neighbors\u001b[39;00m\n\u001b[1;32m    175\u001b[0m segmentation_labels \u001b[38;5;241m=\u001b[39m labels[nearest_neighbors]\u001b[38;5;241m.\u001b[39mreshape(img_shape)\n",
      "File \u001b[0;32m~/mambaforge/envs/autoseg/lib/python3.11/site-packages/scipy/spatial/_kdtree.py:475\u001b[0m, in \u001b[0;36mKDTree.query\u001b[0;34m(self, x, k, eps, p, distance_upper_bound, workers)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk must be an integer or a sequence of integers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 475\u001b[0m d, i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistance_upper_bound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    477\u001b[0m     i \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mintp(i)\n",
      "File \u001b[0;32m_ckdtree.pyx:824\u001b[0m, in \u001b[0;36mscipy.spatial._ckdtree.cKDTree.query\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "# import pydensecrf.densecrf as dcrf\n",
    "\n",
    "# from mgl_v2 import get_mask_mgl\n",
    "import utils.draw\n",
    "import utils.projections\n",
    "import utils.postprocessing\n",
    "# importlib.reload(sys.modules['mgl_v2']) \n",
    "importlib.reload(sys.modules['utils.draw']) \n",
    "\n",
    "importlib.reload(sys.modules['utils.projections']) \n",
    "importlib.reload(sys.modules['utils.postprocessing']) \n",
    "\n",
    "##########################################################################\n",
    "### Begin segmentation projection here\n",
    "##########################################################################\n",
    "print('Starting segmentation estimation')\n",
    "image_paths = sorted(glob.glob(os.path.join(DATA_PATH, 'images/thermal/*')))[2000::1000]\n",
    "for t, img_path in tqdm.tqdm(enumerate(image_paths), total=len(image_paths)):\n",
    "    # if t < 8:\n",
    "    #     continue\n",
    "    # img_path = os.path.join(DATA_PATH, 'images/thermal/thermal-50000.tiff')\n",
    "    # img_path = os.path.join(DATA_PATH, 'images/thermal/thermal-20000.tiff')\n",
    "    # img_path = '/home/carson/data/thermal/2022-05-15_ColoradoRiver/flight3/images/thermal/thermal-02500.tiff'\n",
    "    # output_path = 'outputs/{}'.format(os.path.basename(img_path).replace('tiff', 'png'))\n",
    "\n",
    "    image_data = alignment_data[alignment_data['image'] == \"images/thermal/{}\".format(os.path.basename(img_path))]\n",
    "    # image_data = alignment_data[alignment_data['ir_file'] == \"images/thermal/{}\".format(os.path.basename(img_path))]\n",
    "    if len(image_data) == 0:\n",
    "        print('Skipping {}, no pose info...'.format(img_path))\n",
    "        continue\n",
    "    \n",
    "    coords = image_data[['camLLA_lat', 'camLLA_lon']].values.astype(float)[0]\n",
    "    cam_xyzw = image_data[['camNED_qx', 'camNED_qy', 'camNED_qz', 'camNED_qw']].values.astype(float)[0]\n",
    "    height = image_data[['camNED_D']].values.astype(float)[0, 0]\n",
    "\n",
    "    # coords = image_data[['uav_lat', 'uav_lon']].values.astype(float)[0]\n",
    "    # cam_xyzw = image_data[['ir_qx', 'ir_qy', 'ir_qz', 'ir_qw']].values.astype(float)[0]\n",
    "    # height = image_data[['ir_Z']].values.astype(float)[0, 0]\n",
    "    \n",
    "    dist_to_ground_plane = image_data[['riverNED_Z']].values.astype(float)[0, 0]\n",
    "    if np.isnan(coords).any():\n",
    "        print('Skipping {}, lat/lng (camLLA_lat/lng) has NaNs...'.format(img_path))\n",
    "        continue\n",
    "    if np.isnan(cam_xyzw).any():\n",
    "        print('Skipping {}, quaternion has NaNs...'.format(img_path))\n",
    "        continue\n",
    "    if np.isnan(height).any():\n",
    "        print('Skipping {}, uav altitude (camNED_D) has NaNs...'.format(img_path))\n",
    "        continue\n",
    "    if np.isnan(dist_to_ground_plane).any():\n",
    "        print('Skipping {}, uav to ground distance (riverNED_Z) has NaNs...'.format(img_path))\n",
    "        continue\n",
    "\n",
    "    # print('Processing image: {}'.format(img_path))\n",
    "    img = cv2.imread(img_path, -1)\n",
    "    img = thermal2rgb(img)\n",
    "    undistorted_image = cv2.undistort(img, I, D, None, newcameramtx)\n",
    "\n",
    "    # dist_to_ground_plane = -9\n",
    "    z = height + dist_to_ground_plane\n",
    "    r = Rotation.from_quat(cam_xyzw)\n",
    "    yaw, pitch, roll =  r.as_euler('ZYX', degrees=False)\n",
    "    \n",
    "    Nx = 500\n",
    "    Ny = 300\n",
    "\n",
    "    t0 = time.time()\n",
    "    x_unit_vec, y_unit_vec, x_magnitudes, y_magnitudes, world_pts, xx, yy = utils.projections.create_world_grid(\n",
    "        yaw, \n",
    "        x_mag=10000,\n",
    "        y_mag=8000,\n",
    "        Nx=Nx,\n",
    "        Ny=Ny,\n",
    "        exp_x=3,\n",
    "        exp_y=3,\n",
    "    )\n",
    "    t1 = time.time()\n",
    "    # print('{:3f} seconds to create world grid'.format(t1 - t0))\n",
    "    \n",
    "    utm_e, utm_n = tform.transform(coords[0], coords[1])\n",
    "    rows, cols = rasterio.transform.rowcol(label_tiff_data.transform, xs=utm_e, ys=utm_n)\n",
    "\n",
    "    ptA_utm = np.array([utm_e, utm_n])\n",
    "    ptA_rc = np.array([cols, rows])\n",
    "\n",
    "    # y_grid = y_unit_vec.reshape(2, 1) * y_magnitudes.reshape(1, N)\n",
    "    # x_grid = ptA_utm.reshape(2, 1) + x_unit_vec.reshape(2, 1) * x_magnitudes.reshape(1, N)\n",
    "    # utm_grid = x_grid.T.reshape(N, 1, 2) + y_grid.T.reshape(1, N, 2)\n",
    "\n",
    "    y_grid = y_unit_vec.reshape(2, 1) * yy.reshape(1, Nx*Ny)\n",
    "    x_grid = ptA_utm.reshape(2, 1) + x_unit_vec.reshape(2, 1) * xx.reshape(1, Nx*Ny)\n",
    "    utm_grid = x_grid + y_grid \n",
    "    utm_grid = utm_grid.reshape(2, Ny, Nx).transpose(2, 1, 0)\n",
    "\n",
    "    # t0 = time.time()\n",
    "    # sampled_labels = rasterio.sample.sample_gen(label_tiff_data, xy=utm_grid.reshape(-1, 2))\n",
    "    # sampled_z = rasterio.sample.sample_gen(dsm, xy=utm_grid.reshape(-1, 2))\n",
    "    # t1 = time.time()\n",
    "    # print('{:3f} seconds to sample from rasters'.format(t1 - t0))\n",
    "\n",
    "    t0 = time.time()\n",
    "    # print(utm_grid.shape)\n",
    "    sampled_labels = label_interp(utm_grid.reshape(-1, 2))\n",
    "    sampled_z = dsm_interp(utm_grid.reshape(-1, 2))\n",
    "    t1 = time.time()\n",
    "    # print('{:3f} seconds to sample from array'.format(t1 - t0))\n",
    "\n",
    "    t0 = time.time()\n",
    "    # word_coord_pts = np.zeros((N*N, 4)) # x, y, z, label\n",
    "    # for i, (val, h) in enumerate(zip(sampled_labels, sampled_z)):\n",
    "    #     print(type(val), h)\n",
    "    #     word_coord_pts[i, 0:2] = world_pts[i]\n",
    "    #     word_coord_pts[i, 2] = np.clip(h - BASELINE_ELEVATION, 0, None)\n",
    "    #     word_coord_pts[i, 3] = val[-1] \n",
    "    #     exit(0)\n",
    "\n",
    "    world_coord_z = np.clip(sampled_z.reshape(Nx*Ny, 1) - BASELINE_ELEVATION, 0, None)\n",
    "    word_coord_pts = np.concatenate([world_pts.reshape(Nx*Ny, 2), world_coord_z], axis=1)\n",
    "    N_LULC_CLASSES = 10\n",
    "    # world_coord_labels = sampled_labels.reshape(Nx*Ny, N_LULC_CLASSES)\n",
    "    world_coord_labels = sampled_labels.reshape(Nx*Ny, 1)\n",
    "    # print(\"World Coordinate Labels\", world_coord_labels)\n",
    "    t1 = time.time()\n",
    "    # print('{:3f} seconds to label world coordinates'.format(t1 - t0))\n",
    "\n",
    "    # Label points in back first\n",
    "    # ind = np.argsort(word_coord_pts[:,0])[::-1]\n",
    "    # word_coord_pts = word_coord_pts[ind]\n",
    "    # world_coord_labels = world_coord_labels[ind]\n",
    "    word_coord_pts[:, 2] = -word_coord_pts[:, 2] - z\n",
    "\n",
    "    ### SARASWATI: word_coord_pts are the 3D labels (x: forward, y: right, z: down)\n",
    "    camera_pts = world_to_camera_coords(cam_xyzw, word_coord_pts).T\n",
    "    labeled_camera_pts = np.concatenate([camera_pts, world_coord_labels[:,-1].reshape(-1, 1)], axis=1)\n",
    "    name = os.path.basename(img_path).split('.')[0]\n",
    "    np.save('outputs/{}.npy'.format(name), labeled_camera_pts)\n",
    "\n",
    "    surface_elevation = np.copy(word_coord_pts[:, 2])\n",
    "    \n",
    "    ### SARASWATI: dig into world2cam to find where the word_coord_pts get transformed into the \n",
    "    ### camera coordinate frame (3D), and subsequently, projected into the 2D image frame. \n",
    "    Xn = world2cam(cam_xyzw, new_P, word_coord_pts)\n",
    "\n",
    "    original_img, masked_img, pts_img = utils.draw.draw_overlay_and_labels(\n",
    "        undistorted_image, \n",
    "        points=Xn, \n",
    "        labels=world_coord_labels[:,-1], \n",
    "        color_map=color_map\n",
    "    )\n",
    "\n",
    "    name = os.path.basename(img_path).split('.')[0]\n",
    "    cv2.imwrite('outputs/{}.png'.format(name), original_img)\n",
    "    cv2.imwrite('outputs/{}_autoseg.png'.format(name), masked_img)\n",
    "    cv2.imwrite('outputs/{}_pts.png'.format(name), pts_img)\n",
    "\n",
    "    ### Start postprocessing\n",
    "    probability_img = utils.draw.project_prob(undistorted_image.shape[:2], Xn, world_coord_labels)\n",
    "    surface_img = utils.draw.project_elevation(undistorted_image.shape[:2], Xn, surface_elevation)\n",
    "\n",
    "    thermal_surface_img = np.copy(original_img)\n",
    "    # thermal_surface_img[:,:,2] = surface_img / 1000 * 255\n",
    "    ground_truth_img = np.copy(original_img)\n",
    "    ground_truth_img[:,:,2] = surface_img / 1000 * 255\n",
    "    # params = dict(\n",
    "    #     sxy=(45, 45),\n",
    "    #     srgb=(35, 35, 100), \n",
    "    #     compat=10, \n",
    "    #     kernel=dcrf.FULL_KERNEL, \n",
    "    #     normalization=dcrf.NORMALIZE_SYMMETRIC,\n",
    "    #     inference_steps=3,\n",
    "    # )\n",
    "\n",
    "    # refined_labels = utils.postprocessing.dense_crf(probability_img, thermal_surface_img, **params)\n",
    "    # refined_mask = utils.draw.colorize_dynamic_world_label(refined_labels)\n",
    "    \n",
    "    mgl_mask = get_mask_mgl(labeled_camera_pts.T, None)\n",
    "    \n",
    "    # cv2.imwrite('original_output/{}_autoseg_refined.png'.format(name), cv2.cvtColor(refined_mask, cv2.COLOR_RGB2BGR))\n",
    "    overlay = cv2.addWeighted(original_img, 0.7, mgl_mask, 0.4, 0)\n",
    "    cv2.imwrite('outputs/{}_autoseg_mgl.png'.format(name), cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
